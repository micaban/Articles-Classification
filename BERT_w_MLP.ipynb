{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63527171fa364b92a5983ff6e289b578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e281dc76e4e64785bf11676464812772",
              "IPY_MODEL_f7f4b06b37ca4be38802902e41a150e9",
              "IPY_MODEL_0361169067d340c79337b15958a6717f"
            ],
            "layout": "IPY_MODEL_b21acb8880ee4ec48d4dd81e96ce7708"
          }
        },
        "e281dc76e4e64785bf11676464812772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a3851fff4f460a83829a7e3edba593",
            "placeholder": "​",
            "style": "IPY_MODEL_353195f139c0417b8ce7c95ab8a78122",
            "value": "Downloading: 100%"
          }
        },
        "f7f4b06b37ca4be38802902e41a150e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d026a52a2cf49a99754a683598bcab2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4280711d4a214b88a8230038eb97e7fa",
            "value": 231508
          }
        },
        "0361169067d340c79337b15958a6717f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aba02a38fde745d2a779f11fdbdace80",
            "placeholder": "​",
            "style": "IPY_MODEL_4ee547a9ca93440e8c288363a37c8f83",
            "value": " 232k/232k [00:00&lt;00:00, 591kB/s]"
          }
        },
        "b21acb8880ee4ec48d4dd81e96ce7708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a3851fff4f460a83829a7e3edba593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353195f139c0417b8ce7c95ab8a78122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d026a52a2cf49a99754a683598bcab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4280711d4a214b88a8230038eb97e7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aba02a38fde745d2a779f11fdbdace80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee547a9ca93440e8c288363a37c8f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc4b84773ce43b5a8cc20b1050d6a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_795d7ba2b91e45efabd4970f51440ca6",
              "IPY_MODEL_797571d98a0b4e7284480615b7bbca03",
              "IPY_MODEL_228dc04989804f4a8ad9a0738f89650d"
            ],
            "layout": "IPY_MODEL_92d130f8a24a4b5d980b138432d1158d"
          }
        },
        "795d7ba2b91e45efabd4970f51440ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c63d80466c4571a8fe783ad5256d83",
            "placeholder": "​",
            "style": "IPY_MODEL_1d99204a34df486db4e2b8ececf02b6f",
            "value": "Downloading: 100%"
          }
        },
        "797571d98a0b4e7284480615b7bbca03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe08930ed904492925504e27462ec73",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb442f30b3d848e7978f27ca2d68d505",
            "value": 28
          }
        },
        "228dc04989804f4a8ad9a0738f89650d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998e754d284f49348b6958d4e514490b",
            "placeholder": "​",
            "style": "IPY_MODEL_6c63acc1f913438ea7961126c15d0ef7",
            "value": " 28.0/28.0 [00:00&lt;00:00, 327B/s]"
          }
        },
        "92d130f8a24a4b5d980b138432d1158d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c63d80466c4571a8fe783ad5256d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d99204a34df486db4e2b8ececf02b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe08930ed904492925504e27462ec73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb442f30b3d848e7978f27ca2d68d505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "998e754d284f49348b6958d4e514490b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c63acc1f913438ea7961126c15d0ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b0a691368ef43008f4e4b77eb6a7aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7580f1843e5646fa914b6a5c72661a52",
              "IPY_MODEL_6ca84ddbb63e44e7ad421a6d4b76a4c5",
              "IPY_MODEL_afdedab8fc174d1c9a8b0cb980966bae"
            ],
            "layout": "IPY_MODEL_56c1ea3082754a3f975d93f8c712d7e7"
          }
        },
        "7580f1843e5646fa914b6a5c72661a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fade48031e54dcc984367793d0982c8",
            "placeholder": "​",
            "style": "IPY_MODEL_60c8e8b64e2448529ac13f370486d42d",
            "value": "Downloading: 100%"
          }
        },
        "6ca84ddbb63e44e7ad421a6d4b76a4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7617c2fbe934b9989523c1e8e4f19d2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce9ddf975fb40529ae47213c711c4a9",
            "value": 570
          }
        },
        "afdedab8fc174d1c9a8b0cb980966bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109a84b66a744bcf938efb9d9f870766",
            "placeholder": "​",
            "style": "IPY_MODEL_bdab8f338926474dbb14507026caac31",
            "value": " 570/570 [00:00&lt;00:00, 5.03kB/s]"
          }
        },
        "56c1ea3082754a3f975d93f8c712d7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fade48031e54dcc984367793d0982c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c8e8b64e2448529ac13f370486d42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7617c2fbe934b9989523c1e8e4f19d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce9ddf975fb40529ae47213c711c4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "109a84b66a744bcf938efb9d9f870766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdab8f338926474dbb14507026caac31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7116e65a019e4cac90a62764e2d61b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51bcb35b84f34ced9227e8417233fd4f",
              "IPY_MODEL_461fcc5b5b004c60abb865d686660ae0",
              "IPY_MODEL_aadaaa593b9a4980926031ad4783ad56"
            ],
            "layout": "IPY_MODEL_614d58a3d2bd4faa9ad271782b047705"
          }
        },
        "51bcb35b84f34ced9227e8417233fd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8529a114e23940fe91578522254eb42d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d0641aa74dd4e4a8fd4c49b6d772c00",
            "value": "Downloading: 100%"
          }
        },
        "461fcc5b5b004c60abb865d686660ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f7227ee4efa4027962d227edc9687cb",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4371f8a0cff448b5902158400933c5cc",
            "value": 440473133
          }
        },
        "aadaaa593b9a4980926031ad4783ad56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f64b908d4949de84c6dee57de29013",
            "placeholder": "​",
            "style": "IPY_MODEL_e3cc03c0a785455da31232323f2c52fa",
            "value": " 440M/440M [00:05&lt;00:00, 77.3MB/s]"
          }
        },
        "614d58a3d2bd4faa9ad271782b047705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8529a114e23940fe91578522254eb42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0641aa74dd4e4a8fd4c49b6d772c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f7227ee4efa4027962d227edc9687cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4371f8a0cff448b5902158400933c5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f64b908d4949de84c6dee57de29013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cc03c0a785455da31232323f2c52fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj_eBt3G3bo6"
      },
      "source": [
        "# Dataset\n",
        "-------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt3HTo7LLMtj"
      },
      "source": [
        "## Mounting and reading file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akUxcVFt8V6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd434f87-21e3-4036-d573-0a9d9cd40d76"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the model files back from Google Drive to the Colab instance. \n",
        "#!cp -r \"./drive/My Drive/BERT Document Classification Tutorial/model_save/\" ./model_save/\n",
        "!cp -r \"./drive/My Drive/SemEval2023/t1/data\" ./\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkYdBEK44Abs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76539efd-6912-43b0-e1cd-5b29132b6f5d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('Parsing the dataset .tsv file...')\n",
        "data = pd.read_csv('./data/train_1_all.tsv', sep = '\\t', index_col = 0)\n",
        "print('    Done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing the dataset .tsv file...\n",
            "    Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5J0EPDh-DBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "462a47f3-7507-42f9-e76e-f9dbb87342df"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        text    type\n",
              "id                                                                  \n",
              "833042063  Chelsea Handler Admits She’s ‘Very Sexually At...  satire\n",
              "832959523  How Theresa May Botched\\n\\nThose were the time...  satire\n",
              "833039623  Robert Mueller III Rests His Case—Dems NEVER W...  satire\n",
              "833032367  Robert Mueller Not Recommending Any More Indic...  satire\n",
              "814777937  The Far Right Is Trying to Co-opt the Yellow V...  satire"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f9dc076-0d43-46cf-b3c0-a92ebf659689\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>833042063</th>\n",
              "      <td>Chelsea Handler Admits She’s ‘Very Sexually At...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832959523</th>\n",
              "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833039623</th>\n",
              "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833032367</th>\n",
              "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814777937</th>\n",
              "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
              "      <td>satire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f9dc076-0d43-46cf-b3c0-a92ebf659689')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f9dc076-0d43-46cf-b3c0-a92ebf659689 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f9dc076-0d43-46cf-b3c0-a92ebf659689');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON6STifKn_UW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "4453b6e2-a286-4c29-ceb1-996c09ad201c"
      },
      "source": [
        "data.groupby('type').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text\n",
              "type           \n",
              "opinion     382\n",
              "reporting   180\n",
              "satire       63"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20041949-380a-4799-8d76-44a70c71fcd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>opinion</th>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reporting</th>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>satire</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20041949-380a-4799-8d76-44a70c71fcd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20041949-380a-4799-8d76-44a70c71fcd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20041949-380a-4799-8d76-44a70c71fcd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXeWYWkGI8wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f7b638-6e7e-4abb-bf00-723e54444eb7"
      },
      "source": [
        "total_comments = len(data)\n",
        "num_attacks=382\n",
        "\n",
        "print('{:,} of {:,} articles are opinion ({:.2%})'.format(num_attacks, total_comments, num_attacks/total_comments))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "382 of 625 articles are opinion (61.12%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "BSxodMZdn-iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "data[\"n_words\"]=data['text'].apply(lambda x: len(str(x).split()))\n",
        "data[\"n_words_unique\"]=data['text'].apply(lambda x: len(set(str(x).split())))\n",
        "data[\"n_stopwords\"]=data['text'].apply(lambda x: len([w for w in str(x).split() if w in stopwords.words('english')]))\n",
        "data[\"n_punct\"]=data['text'].apply(lambda x: len([w for w in str(x) if w in list(string.punctuation)]))\n",
        "data[\"mean_w_len\"]=data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "data[\"n_parag\"]=data['text'].apply(lambda x: len(x.split('\\n')))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "dXdwIRMzoCfC",
        "outputId": "6f499368-8f29-48aa-afa6-75bc060229aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        text    type  n_words  \\\n",
              "id                                                                              \n",
              "833042063  Chelsea Handler Admits She’s ‘Very Sexually At...  satire      338   \n",
              "832959523  How Theresa May Botched\\n\\nThose were the time...  satire      859   \n",
              "833039623  Robert Mueller III Rests His Case—Dems NEVER W...  satire     1174   \n",
              "833032367  Robert Mueller Not Recommending Any More Indic...  satire      630   \n",
              "814777937  The Far Right Is Trying to Co-opt the Yellow V...  satire      899   \n",
              "\n",
              "           n_words_unique  n_stopwords  n_punct  mean_w_len  n_parag  \n",
              "id                                                                    \n",
              "833042063             204          126       43    5.192308       18  \n",
              "832959523             457          325      120    4.668219       56  \n",
              "833039623             630          453      154    5.045145       40  \n",
              "833032367             377          214       89    5.342857       39  \n",
              "814777937             472          278      167    5.560623       49  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c23422f9-005c-4cea-83c6-fb367d121eb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>n_words</th>\n",
              "      <th>n_words_unique</th>\n",
              "      <th>n_stopwords</th>\n",
              "      <th>n_punct</th>\n",
              "      <th>mean_w_len</th>\n",
              "      <th>n_parag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>833042063</th>\n",
              "      <td>Chelsea Handler Admits She’s ‘Very Sexually At...</td>\n",
              "      <td>satire</td>\n",
              "      <td>338</td>\n",
              "      <td>204</td>\n",
              "      <td>126</td>\n",
              "      <td>43</td>\n",
              "      <td>5.192308</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832959523</th>\n",
              "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
              "      <td>satire</td>\n",
              "      <td>859</td>\n",
              "      <td>457</td>\n",
              "      <td>325</td>\n",
              "      <td>120</td>\n",
              "      <td>4.668219</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833039623</th>\n",
              "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
              "      <td>satire</td>\n",
              "      <td>1174</td>\n",
              "      <td>630</td>\n",
              "      <td>453</td>\n",
              "      <td>154</td>\n",
              "      <td>5.045145</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833032367</th>\n",
              "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
              "      <td>satire</td>\n",
              "      <td>630</td>\n",
              "      <td>377</td>\n",
              "      <td>214</td>\n",
              "      <td>89</td>\n",
              "      <td>5.342857</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814777937</th>\n",
              "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
              "      <td>satire</td>\n",
              "      <td>899</td>\n",
              "      <td>472</td>\n",
              "      <td>278</td>\n",
              "      <td>167</td>\n",
              "      <td>5.560623</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c23422f9-005c-4cea-83c6-fb367d121eb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c23422f9-005c-4cea-83c6-fb367d121eb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c23422f9-005c-4cea-83c6-fb367d121eb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def conntractionsCount(text):\n",
        "  count = 0\n",
        "  count += re.subn(r\"n\\'t\",'', text)[1]\n",
        "  count += re.subn(r\"\\'re\",'', text)[1]\n",
        "  count += re.subn(r\"\\'s\",'', text)[1]\n",
        "  count += re.subn(r\"\\'ll\",'', text)[1]\n",
        "  count += re.subn(r\"\\'t\",'', text)[1]\n",
        "  count += re.subn(r\"\\'ve\",'', text)[1]\n",
        "  count += re.subn(r\"\\'m\",'', text)[1]\n",
        "  return count\n",
        "\n",
        "data[\"n_contract\"]= data['text'].apply(conntractionsCount)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dvp6Mgpxw_et",
        "outputId": "97faa923-0f88-4539-e987-c507adfc0a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        text    type  n_words  \\\n",
              "id                                                                              \n",
              "833042063  Chelsea Handler Admits She’s ‘Very Sexually At...  satire      338   \n",
              "832959523  How Theresa May Botched\\n\\nThose were the time...  satire      859   \n",
              "833039623  Robert Mueller III Rests His Case—Dems NEVER W...  satire     1174   \n",
              "833032367  Robert Mueller Not Recommending Any More Indic...  satire      630   \n",
              "814777937  The Far Right Is Trying to Co-opt the Yellow V...  satire      899   \n",
              "\n",
              "           n_words_unique  n_stopwords  n_punct  mean_w_len  n_parag  \\\n",
              "id                                                                     \n",
              "833042063             204          126       43    5.192308       18   \n",
              "832959523             457          325      120    4.668219       56   \n",
              "833039623             630          453      154    5.045145       40   \n",
              "833032367             377          214       89    5.342857       39   \n",
              "814777937             472          278      167    5.560623       49   \n",
              "\n",
              "           n_contract  \n",
              "id                     \n",
              "833042063           0  \n",
              "832959523           0  \n",
              "833039623           0  \n",
              "833032367           4  \n",
              "814777937           3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d40d7164-2fc4-457d-a162-485f4142fae3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>n_words</th>\n",
              "      <th>n_words_unique</th>\n",
              "      <th>n_stopwords</th>\n",
              "      <th>n_punct</th>\n",
              "      <th>mean_w_len</th>\n",
              "      <th>n_parag</th>\n",
              "      <th>n_contract</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>833042063</th>\n",
              "      <td>Chelsea Handler Admits She’s ‘Very Sexually At...</td>\n",
              "      <td>satire</td>\n",
              "      <td>338</td>\n",
              "      <td>204</td>\n",
              "      <td>126</td>\n",
              "      <td>43</td>\n",
              "      <td>5.192308</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832959523</th>\n",
              "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
              "      <td>satire</td>\n",
              "      <td>859</td>\n",
              "      <td>457</td>\n",
              "      <td>325</td>\n",
              "      <td>120</td>\n",
              "      <td>4.668219</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833039623</th>\n",
              "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
              "      <td>satire</td>\n",
              "      <td>1174</td>\n",
              "      <td>630</td>\n",
              "      <td>453</td>\n",
              "      <td>154</td>\n",
              "      <td>5.045145</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833032367</th>\n",
              "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
              "      <td>satire</td>\n",
              "      <td>630</td>\n",
              "      <td>377</td>\n",
              "      <td>214</td>\n",
              "      <td>89</td>\n",
              "      <td>5.342857</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814777937</th>\n",
              "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
              "      <td>satire</td>\n",
              "      <td>899</td>\n",
              "      <td>472</td>\n",
              "      <td>278</td>\n",
              "      <td>167</td>\n",
              "      <td>5.560623</td>\n",
              "      <td>49</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d40d7164-2fc4-457d-a162-485f4142fae3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d40d7164-2fc4-457d-a162-485f4142fae3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d40d7164-2fc4-457d-a162-485f4142fae3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "data[\"polarity\"]= data['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "data[\"subjectivity\"]= data['text'].apply(lambda x: TextBlob(x).sentiment[1])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "Ha8rHGIed2EV",
        "outputId": "37f6041f-f5d9-4238-dd2b-9ee61545b31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        text    type  n_words  \\\n",
              "id                                                                              \n",
              "833042063  Chelsea Handler Admits She’s ‘Very Sexually At...  satire      338   \n",
              "832959523  How Theresa May Botched\\n\\nThose were the time...  satire      859   \n",
              "833039623  Robert Mueller III Rests His Case—Dems NEVER W...  satire     1174   \n",
              "833032367  Robert Mueller Not Recommending Any More Indic...  satire      630   \n",
              "814777937  The Far Right Is Trying to Co-opt the Yellow V...  satire      899   \n",
              "\n",
              "           n_words_unique  n_stopwords  n_punct  mean_w_len  n_parag  \\\n",
              "id                                                                     \n",
              "833042063             204          126       43    5.192308       18   \n",
              "832959523             457          325      120    4.668219       56   \n",
              "833039623             630          453      154    5.045145       40   \n",
              "833032367             377          214       89    5.342857       39   \n",
              "814777937             472          278      167    5.560623       49   \n",
              "\n",
              "           n_contract  polarity  subjectivity  \n",
              "id                                             \n",
              "833042063           0  0.251403      0.604804  \n",
              "832959523           0  0.033830      0.421623  \n",
              "833039623           0 -0.003652      0.456504  \n",
              "833032367           4  0.109822      0.452223  \n",
              "814777937           3  0.043860      0.306572  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cf6a809-de31-4904-9adc-c6524a0e5337\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>n_words</th>\n",
              "      <th>n_words_unique</th>\n",
              "      <th>n_stopwords</th>\n",
              "      <th>n_punct</th>\n",
              "      <th>mean_w_len</th>\n",
              "      <th>n_parag</th>\n",
              "      <th>n_contract</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>833042063</th>\n",
              "      <td>Chelsea Handler Admits She’s ‘Very Sexually At...</td>\n",
              "      <td>satire</td>\n",
              "      <td>338</td>\n",
              "      <td>204</td>\n",
              "      <td>126</td>\n",
              "      <td>43</td>\n",
              "      <td>5.192308</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.251403</td>\n",
              "      <td>0.604804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832959523</th>\n",
              "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
              "      <td>satire</td>\n",
              "      <td>859</td>\n",
              "      <td>457</td>\n",
              "      <td>325</td>\n",
              "      <td>120</td>\n",
              "      <td>4.668219</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033830</td>\n",
              "      <td>0.421623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833039623</th>\n",
              "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
              "      <td>satire</td>\n",
              "      <td>1174</td>\n",
              "      <td>630</td>\n",
              "      <td>453</td>\n",
              "      <td>154</td>\n",
              "      <td>5.045145</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.003652</td>\n",
              "      <td>0.456504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833032367</th>\n",
              "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
              "      <td>satire</td>\n",
              "      <td>630</td>\n",
              "      <td>377</td>\n",
              "      <td>214</td>\n",
              "      <td>89</td>\n",
              "      <td>5.342857</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "      <td>0.109822</td>\n",
              "      <td>0.452223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814777937</th>\n",
              "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
              "      <td>satire</td>\n",
              "      <td>899</td>\n",
              "      <td>472</td>\n",
              "      <td>278</td>\n",
              "      <td>167</td>\n",
              "      <td>5.560623</td>\n",
              "      <td>49</td>\n",
              "      <td>3</td>\n",
              "      <td>0.043860</td>\n",
              "      <td>0.306572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cf6a809-de31-4904-9adc-c6524a0e5337')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cf6a809-de31-4904-9adc-c6524a0e5337 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cf6a809-de31-4904-9adc-c6524a0e5337');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "def pos_count(sent):\n",
        "    nn_count = 0   #Noun\n",
        "    pr_count = 0   #Pronoun\n",
        "    vb_count = 0   #Verb\n",
        "    jj_count = 0   #Adjective\n",
        "    uh_count = 0   #Interjection\n",
        "    cd_count = 0   #Numerics\n",
        "    \n",
        "    sent = nltk.word_tokenize(sent)\n",
        "    sent = nltk.pos_tag(sent)\n",
        "    for token in sent:\n",
        "      if token[1] in ['NN','NNP','NNS']:\n",
        "        nn_count += 1\n",
        "      if token[1] in ['PRP','PRP$']:\n",
        "        pr_count += 1\n",
        "      if token[1] in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
        "        vb_count += 1\n",
        "      if token[1] in ['JJ','JJR','JJS']:\n",
        "        jj_count += 1\n",
        "      if token[1] in ['UH']:\n",
        "        uh_count += 1\n",
        "      if token[1] in ['CD']:\n",
        "        cd_count += 1\n",
        "        \n",
        "    return pd.Series([nn_count, pr_count, vb_count, jj_count, uh_count, cd_count])\n",
        "\n",
        "\n",
        "data[['nn_count', 'pr_count', 'vb_count', 'jj_count', 'uh_count', 'cd_count']]= data['text'].apply(pos_count)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "LacDLoDKg8jz",
        "outputId": "4f61513a-8242-4824-e9a6-c61b553d0df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        text    type  n_words  \\\n",
              "id                                                                              \n",
              "833042063  Chelsea Handler Admits She’s ‘Very Sexually At...  satire      338   \n",
              "832959523  How Theresa May Botched\\n\\nThose were the time...  satire      859   \n",
              "833039623  Robert Mueller III Rests His Case—Dems NEVER W...  satire     1174   \n",
              "833032367  Robert Mueller Not Recommending Any More Indic...  satire      630   \n",
              "814777937  The Far Right Is Trying to Co-opt the Yellow V...  satire      899   \n",
              "\n",
              "           n_words_unique  n_stopwords  n_punct  mean_w_len  n_parag  \\\n",
              "id                                                                     \n",
              "833042063             204          126       43    5.192308       18   \n",
              "832959523             457          325      120    4.668219       56   \n",
              "833039623             630          453      154    5.045145       40   \n",
              "833032367             377          214       89    5.342857       39   \n",
              "814777937             472          278      167    5.560623       49   \n",
              "\n",
              "           n_contract  polarity  subjectivity  nn_count  pr_count  vb_count  \\\n",
              "id                                                                            \n",
              "833042063           0  0.251403      0.604804       135        38        64   \n",
              "832959523           0  0.033830      0.421623       283        49       158   \n",
              "833039623           0 -0.003652      0.456504       390        43       215   \n",
              "833032367           4  0.109822      0.452223       280        38        93   \n",
              "814777937           3  0.043860      0.306572       372        27       146   \n",
              "\n",
              "           jj_count  uh_count  cd_count  \n",
              "id                                       \n",
              "833042063        25         0         2  \n",
              "832959523        59         1        23  \n",
              "833039623        98         0        13  \n",
              "833032367        42         2         2  \n",
              "814777937       112         0         6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-073496a3-5cae-487f-8a82-d7aa1b34b89b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>n_words</th>\n",
              "      <th>n_words_unique</th>\n",
              "      <th>n_stopwords</th>\n",
              "      <th>n_punct</th>\n",
              "      <th>mean_w_len</th>\n",
              "      <th>n_parag</th>\n",
              "      <th>n_contract</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>nn_count</th>\n",
              "      <th>pr_count</th>\n",
              "      <th>vb_count</th>\n",
              "      <th>jj_count</th>\n",
              "      <th>uh_count</th>\n",
              "      <th>cd_count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>833042063</th>\n",
              "      <td>Chelsea Handler Admits She’s ‘Very Sexually At...</td>\n",
              "      <td>satire</td>\n",
              "      <td>338</td>\n",
              "      <td>204</td>\n",
              "      <td>126</td>\n",
              "      <td>43</td>\n",
              "      <td>5.192308</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.251403</td>\n",
              "      <td>0.604804</td>\n",
              "      <td>135</td>\n",
              "      <td>38</td>\n",
              "      <td>64</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832959523</th>\n",
              "      <td>How Theresa May Botched\\n\\nThose were the time...</td>\n",
              "      <td>satire</td>\n",
              "      <td>859</td>\n",
              "      <td>457</td>\n",
              "      <td>325</td>\n",
              "      <td>120</td>\n",
              "      <td>4.668219</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033830</td>\n",
              "      <td>0.421623</td>\n",
              "      <td>283</td>\n",
              "      <td>49</td>\n",
              "      <td>158</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833039623</th>\n",
              "      <td>Robert Mueller III Rests His Case—Dems NEVER W...</td>\n",
              "      <td>satire</td>\n",
              "      <td>1174</td>\n",
              "      <td>630</td>\n",
              "      <td>453</td>\n",
              "      <td>154</td>\n",
              "      <td>5.045145</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.003652</td>\n",
              "      <td>0.456504</td>\n",
              "      <td>390</td>\n",
              "      <td>43</td>\n",
              "      <td>215</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833032367</th>\n",
              "      <td>Robert Mueller Not Recommending Any More Indic...</td>\n",
              "      <td>satire</td>\n",
              "      <td>630</td>\n",
              "      <td>377</td>\n",
              "      <td>214</td>\n",
              "      <td>89</td>\n",
              "      <td>5.342857</td>\n",
              "      <td>39</td>\n",
              "      <td>4</td>\n",
              "      <td>0.109822</td>\n",
              "      <td>0.452223</td>\n",
              "      <td>280</td>\n",
              "      <td>38</td>\n",
              "      <td>93</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814777937</th>\n",
              "      <td>The Far Right Is Trying to Co-opt the Yellow V...</td>\n",
              "      <td>satire</td>\n",
              "      <td>899</td>\n",
              "      <td>472</td>\n",
              "      <td>278</td>\n",
              "      <td>167</td>\n",
              "      <td>5.560623</td>\n",
              "      <td>49</td>\n",
              "      <td>3</td>\n",
              "      <td>0.043860</td>\n",
              "      <td>0.306572</td>\n",
              "      <td>372</td>\n",
              "      <td>27</td>\n",
              "      <td>146</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-073496a3-5cae-487f-8a82-d7aa1b34b89b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-073496a3-5cae-487f-8a82-d7aa1b34b89b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-073496a3-5cae-487f-8a82-d7aa1b34b89b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl12-BD637Ty"
      },
      "source": [
        "# BERT Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the model files back from Google Drive to the Colab instance. \n",
        "#!cp -r \"./drive/My Drive/BERT Document Classification Tutorial/model_save/\" ./model_save/\n",
        "!cp -r \"./drive/My Drive/SemEval2023/t1/data\" ./"
      ],
      "metadata": {
        "id": "kPyUJQrz4-Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83131949-1b43-4755-e88a-91511ccdef6e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries Mod"
      ],
      "metadata": {
        "id": "YV7qs7sVnzew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"mlp can specify number of hidden layers and hidden layer channels\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, act='relu', num_hidden_lyr=2,\n",
        "                 dropout_prob=0.5, return_layer_outs=False,\n",
        "                 hidden_channels=None, bn=False):\n",
        "        super().__init__()\n",
        "        self.out_dim = output_dim\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.return_layer_outs = return_layer_outs\n",
        "        if not hidden_channels:\n",
        "            hidden_channels = [input_dim for _ in range(num_hidden_lyr)]\n",
        "        elif len(hidden_channels) != num_hidden_lyr:\n",
        "            raise ValueError(\n",
        "                \"number of hidden layers should be the same as the lengh of hidden_channels\")\n",
        "        self.layer_channels = [input_dim] + hidden_channels + [output_dim]\n",
        "        self.act_name = 'relu'#act\n",
        "        self.activation = nn.ReLU()#create_act(act)\n",
        "        self.layers = nn.ModuleList(list(\n",
        "            map(self.weight_init, [nn.Linear(self.layer_channels[i], self.layer_channels[i + 1])\n",
        "                                   for i in range(len(self.layer_channels) - 2)])))\n",
        "        final_layer = nn.Linear(self.layer_channels[-2], self.layer_channels[-1])\n",
        "        self.weight_init(final_layer,   activation='linear')\n",
        "        self.layers.append(final_layer)\n",
        "\n",
        "        self.bn = bn\n",
        "        if self.bn:\n",
        "            self.bn = nn.ModuleList([torch.nn.BatchNorm1d(dim) for dim in self.layer_channels[1:-1]])\n",
        "\n",
        "    def weight_init(self, m, activation=None):\n",
        "        if activation is None:\n",
        "            activation = self.act_name\n",
        "        torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain(activation))\n",
        "        return m\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: the input features\n",
        "        :return: tuple containing output of MLP,\n",
        "                and list of inputs and outputs at every layer\n",
        "        \"\"\"\n",
        "        layer_inputs = [x]\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            input = layer_inputs[-1]\n",
        "            if layer == self.layers[-1]:\n",
        "                layer_inputs.append(layer(input))\n",
        "            else:\n",
        "                if self.bn:\n",
        "                    output = self.activation(self.bn[i](layer(input)))\n",
        "                else:\n",
        "                    output = self.activation(layer(input))\n",
        "                layer_inputs.append(self.dropout(output))\n",
        "\n",
        "        # model.store_layer_output(self, layer_inputs[-1])\n",
        "        if self.return_layer_outs:\n",
        "            return layer_inputs[-1], layer_inputs\n",
        "        else:\n",
        "            return layer_inputs[-1]"
      ],
      "metadata": {
        "id": "liORyraRfLxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import (\n",
        "    BertForSequenceClassification\n",
        ")\n",
        "\n",
        "class BertConcatFeatures(BertForSequenceClassification):\n",
        "    \"\"\"\n",
        "    Bert Model transformer with a sequence classification/regression head as well as\n",
        "    a TabularFeatCombiner module to combine categorical and numerical features\n",
        "    with the Bert pooled output\n",
        "\n",
        "    Parameters:\n",
        "        hf_model_config (:class:`~transformers.BertConfig`):\n",
        "            Model configuration class with all the parameters of the model.\n",
        "            This object must also have a tabular_config member variable that is a\n",
        "            :obj:`TabularConfig` instance specifying the configs for :obj:`TabularFeatCombiner`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hf_model_config):\n",
        "        super().__init__(hf_model_config)\n",
        "\n",
        "        # ===================================\n",
        "        #   FEATURE COMBINATION SETUP\n",
        "        # ===================================\n",
        "\n",
        "        self.num_labels = hf_model_config.num_labels\n",
        "\n",
        "        combined_feat_dim = hf_model_config.text_feat_dim + \\\n",
        "                            hf_model_config.cat_feat_dim + \\\n",
        "                            hf_model_config.numerical_feat_dim\n",
        "        \n",
        "\n",
        "        self.num_bn = nn.BatchNorm1d(hf_model_config.numerical_feat_dim)\n",
        "\n",
        "        # ===================================\n",
        "        #  MLP SETUP\n",
        "        # ===================================\n",
        "\n",
        "        dims=[]\n",
        "        dim = combined_feat_dim\n",
        "\n",
        "        while True:\n",
        "          dim = dim // 4 #could be changed is how is reduced the dimension by layer\n",
        "          #if resulting layer size is smaller that the num outputs we are done\n",
        "          if dim <= self.num_labels:\n",
        "            break\n",
        "          #if not store as next layer\n",
        "          dims.append(int(dim))\n",
        "\n",
        "        print('MLP layer sizes:')\n",
        "        print(' Input:', combined_feat_dim)\n",
        "        print(' Hidden:', dims)\n",
        "        print(' Output:', self.num_labels)\n",
        "\n",
        "        self.mlp = MLP(combined_feat_dim,\n",
        "                      self.num_labels,\n",
        "                      num_hidden_lyr=len(dims),\n",
        "                      dropout_prob=0.1,#self.mlp_dropout,\n",
        "                      hidden_channels=dims,\n",
        "                      bn=True)\n",
        "        \n",
        "   # @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING.format(\"(batch_size, sequence_length)\"))\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        class_weights=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        cat_feats=None,\n",
        "        numerical_feats=None\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        class_weights (:obj:`torch.FloatTensor` of shape :obj:`(tabular_config.num_labels,)`, `optional`, defaults to :obj:`None`):\n",
        "            Class weights to be used for cross entropy loss function for classification task\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
        "            Labels for computing the sequence classification/regression loss.\n",
        "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
        "            If :obj:`tabular_config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
        "            If :obj:`tabular_config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        cat_feats (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, tabular_config.cat_feat_dim)`, `optional`, defaults to :obj:`None`):\n",
        "            Categorical features to be passed in to the TabularFeatCombiner\n",
        "        numerical_feats (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, tabular_config.numerical_feat_dim)`, `optional`, defaults to :obj:`None`):\n",
        "            Numerical features to be passed in to the TabularFeatCombiner\n",
        "    Returns:\n",
        "        :obj:`tuple` comprising various elements depending on configuration and inputs:\n",
        "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
        "            Classification (or regression if tabular_config.num_labels==1) loss.\n",
        "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, tabular_config.num_labels)`):\n",
        "            Classification (or regression if tabular_config.num_labels==1) scores (before SoftMax).\n",
        "        classifier_layer_outputs(:obj:`list` of :obj:`torch.FloatTensor`):\n",
        "            The outputs of each layer of the final classification layers. The 0th index of this list is the\n",
        "            combining module's output\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        # ===================================\n",
        "        #               BERT\n",
        "        # ===================================\n",
        "\n",
        "        #Run the text through the BERT model invoking self.bert\n",
        "        #Returns outputs from encoding layers, and not from the final classifier\n",
        "        \n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        # ===================================\n",
        "        #           Concat Features\n",
        "        # ===================================\n",
        "\n",
        "        numerical_feats = self.num_bn(numerical_feats)\n",
        "\n",
        "        #Object sizes:\n",
        "        # pooled_output   [batch size x 768]\n",
        "        # numerical_feats [batch size x #numerical features]\n",
        "        # cat_feats       [batch size x #categorical features]\n",
        "\n",
        "\n",
        "        #Concat everything to one vecto\n",
        "        combined_feats = torch.cat((pooled_output, cat_feats, numerical_feats), dim=1)\n",
        "\n",
        "\n",
        "        # ===================================\n",
        "        #           Output Classifier\n",
        "        # ===================================\n",
        "\n",
        "        logits = self.mlp(combined_feats)\n",
        "\n",
        "        #if type(logits) is tuple:\n",
        "        logits, classifier_layer_outputs = logits[0], logits[1]\n",
        "        #else:  # simple classifier\n",
        "        #classifier_layer_outputs = [combined_feats, logits]\n",
        "\n",
        "        # ===================================\n",
        "        #           Output Classifier\n",
        "        # ===================================\n",
        "        #Calculate loss only if labels are passed (not in test)\n",
        "        if labels is not None:\n",
        "          if self.num_labels == 1:\n",
        "            #  We are doing regression\n",
        "            loss_fct = MSELoss()\n",
        "            labels = labels.float()\n",
        "            loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "          else:\n",
        "            loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "            labels = labels.long()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        else:\n",
        "          loss = None\n",
        "        '''\n",
        "        loss, logits, classifier_layer_outputs = hf_loss_func(combined_feats,\n",
        "                                                                self.tabular_classifier,\n",
        "                                                                labels,\n",
        "                                                                self.num_labels,\n",
        "                                                                class_weights)\n",
        "        return loss, logits, classifier_layer_outputs\n",
        "        '''\n",
        "        results={'loss': loss,\n",
        "                 'logits': logits,\n",
        "                 'classifier_layer_outputs':classifier_layer_outputs}\n",
        "        return results"
      ],
      "metadata": {
        "id": "LgEpnqC2famd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "\n",
        "\n",
        "class TorchTabularTextDataset(TorchDataset):\n",
        "    \"\"\"\n",
        "    :obj:`TorchDataset` wrapper for text dataset with categorical features\n",
        "    and numerical features\n",
        "\n",
        "    Parameters:\n",
        "        encodings (:class:`transformers.BatchEncoding`):\n",
        "            The output from encode_plus() and batch_encode() methods (tokens, attention_masks, etc) of\n",
        "            a transformers.PreTrainedTokenizer\n",
        "        categorical_feats (:class:`numpy.ndarray`, of shape :obj:`(n_examples, categorical feat dim)`, `optional`, defaults to :obj:`None`):\n",
        "            An array containing the preprocessed categorical features\n",
        "        numerical_feats (:class:`numpy.ndarray`, of shape :obj:`(n_examples, numerical feat dim)`, `optional`, defaults to :obj:`None`):\n",
        "            An array containing the preprocessed numerical features\n",
        "        labels (:class: list` or `numpy.ndarray`, `optional`, defaults to :obj:`None`):\n",
        "            The labels of the training examples\n",
        "        class_weights (:class:`numpy.ndarray`, of shape (n_classes),  `optional`, defaults to :obj:`None`):\n",
        "            Class weights used for cross entropy loss for classification\n",
        "        df (:class:`pandas.DataFrame`, `optional`, defaults to :obj:`None`):\n",
        "            Model configuration class with all the parameters of the model.\n",
        "            This object must also have a tabular_config member variable that is a\n",
        "            TabularConfig instance specifying the configs for TabularFeatCombiner\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 encodings,\n",
        "                 categorical_feats,\n",
        "                 numerical_feats,\n",
        "                 labels=None,\n",
        "                 df=None,\n",
        "                 label_list=None,\n",
        "                 class_weights=None\n",
        "                 ):\n",
        "        self.df = df\n",
        "        self.encodings = encodings\n",
        "        self.cat_feats = categorical_feats\n",
        "        self.numerical_feats = numerical_feats\n",
        "        self.labels = labels\n",
        "        self.class_weights = class_weights\n",
        "        self.label_list = label_list if label_list is not None else [i for i in range(len(np.unique(labels)))]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx])\n",
        "                for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]) if self.labels is not None  else None\n",
        "        item['cat_feats'] = torch.tensor(self.cat_feats[idx]).float() \\\n",
        "            if self.cat_feats is not None else torch.zeros(0)\n",
        "        item['numerical_feats'] = torch.tensor(self.numerical_feats[idx]).float()\\\n",
        "            if self.numerical_feats is not None else torch.zeros(0)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"returns the label names for classification\"\"\"\n",
        "        return self.label_list\n"
      ],
      "metadata": {
        "id": "JciFPEbK-10o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Text Features - Tokenize and encode text"
      ],
      "metadata": {
        "id": "v5-9XAQInhtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "63527171fa364b92a5983ff6e289b578",
            "e281dc76e4e64785bf11676464812772",
            "f7f4b06b37ca4be38802902e41a150e9",
            "0361169067d340c79337b15958a6717f",
            "b21acb8880ee4ec48d4dd81e96ce7708",
            "23a3851fff4f460a83829a7e3edba593",
            "353195f139c0417b8ce7c95ab8a78122",
            "9d026a52a2cf49a99754a683598bcab2",
            "4280711d4a214b88a8230038eb97e7fa",
            "aba02a38fde745d2a779f11fdbdace80",
            "4ee547a9ca93440e8c288363a37c8f83",
            "7dc4b84773ce43b5a8cc20b1050d6a96",
            "795d7ba2b91e45efabd4970f51440ca6",
            "797571d98a0b4e7284480615b7bbca03",
            "228dc04989804f4a8ad9a0738f89650d",
            "92d130f8a24a4b5d980b138432d1158d",
            "b0c63d80466c4571a8fe783ad5256d83",
            "1d99204a34df486db4e2b8ececf02b6f",
            "8fe08930ed904492925504e27462ec73",
            "fb442f30b3d848e7978f27ca2d68d505",
            "998e754d284f49348b6958d4e514490b",
            "6c63acc1f913438ea7961126c15d0ef7",
            "1b0a691368ef43008f4e4b77eb6a7aa9",
            "7580f1843e5646fa914b6a5c72661a52",
            "6ca84ddbb63e44e7ad421a6d4b76a4c5",
            "afdedab8fc174d1c9a8b0cb980966bae",
            "56c1ea3082754a3f975d93f8c712d7e7",
            "0fade48031e54dcc984367793d0982c8",
            "60c8e8b64e2448529ac13f370486d42d",
            "c7617c2fbe934b9989523c1e8e4f19d2",
            "dce9ddf975fb40529ae47213c711c4a9",
            "109a84b66a744bcf938efb9d9f870766",
            "bdab8f338926474dbb14507026caac31"
          ]
        },
        "id": "qDMGlkdjnuxZ",
        "outputId": "a8a465ba-f08e-42a0-ee8a-739756375e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63527171fa364b92a5983ff6e289b578"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc4b84773ce43b5a8cc20b1050d6a96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b0a691368ef43008f4e4b77eb6a7aa9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''print('   Min length: {:,} tokens'.format(min(lengths)))\n",
        "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
        "print('Median length: {:,} tokens'.format(np.median(lengths)))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKz5DN45p8fv",
        "outputId": "4c371e99-9e1d-4bca-bc55-92532eedcabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Min length: 145 tokens\n",
            "   Max length: 512 tokens\n",
            "Median length: 512.0 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Count the number of sentences that had to be truncated to 512 tokens.\n",
        "num_truncated = lengths.count(512)\n",
        "\n",
        "# Compare this to the total number of training sentences.\n",
        "num_sentences = len(lengths)\n",
        "prcnt = float(num_truncated) / float(num_sentences)\n",
        "\n",
        "print('{:,} of {:,} articles ({:.1%}) in the training set are longer than 512 tokens.'.format(num_truncated, num_sentences, prcnt))\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iofvRyhOqb0w",
        "outputId": "24b8a704-c1bb-4496-85d7-09483985e380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "449 of 625 articles (71.8%) in the training set are longer than 512 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import types\n",
        "#import logger\n",
        "from sklearn.model_selection import train_test_split,KFold\n",
        "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
        "from functools import partial\n",
        "def convert_to_func(container_arg):\n",
        "    \"\"\"convert container_arg to function that returns True if an element is in container_arg\"\"\"\n",
        "    if container_arg is None:\n",
        "        return lambda df, x: False\n",
        "    if not isinstance(container_arg, types.FunctionType):\n",
        "        #print(type(container_arg))\n",
        "        assert type(container_arg) is list or type(container_arg) is set\n",
        "        return lambda df, x: x in container_arg\n",
        "    else:\n",
        "        return container_arg\n",
        "\n",
        "def load_num_feats(df, num_bool_func):\n",
        "    num_cols = get_matching_cols(df, num_bool_func)\n",
        "    print(f'{len(num_cols)} numerical columns')\n",
        "    df = df.copy()\n",
        "    df[num_cols] = df[num_cols].astype(float)\n",
        "    df[num_cols] = df[num_cols].fillna(dict(df[num_cols].median()), inplace=False)\n",
        "    if len(num_cols) == 0:\n",
        "        return None\n",
        "    return df[num_cols].values\n",
        "\n",
        "def load_cat_feats(df, cat_bool_func, encode_type=None):\n",
        "    \"\"\"load categorical features from DataFrame and do encoding if specified\"\"\"\n",
        "    cat_cols = get_matching_cols(df, cat_bool_func)\n",
        "    print(f'{len(cat_cols)} categorical columns')\n",
        "    if len(cat_cols) == 0:\n",
        "        return None\n",
        "    #cat_feat_processor = CategoricalFeatures(df, cat_cols, encode_type)\n",
        "    return None#cat_feat_processor.fit_transform()\n",
        "\n",
        "def get_matching_cols(df, col_match_func):\n",
        "    return [c for c in df.columns if col_match_func(df, c)]\n",
        "\n",
        "def load_cat_and_num_feats(df, cat_bool_func, num_bool_func, enocde_type=None):\n",
        "    cat_feats = load_cat_feats(df, cat_bool_func, enocde_type)\n",
        "    num_feats = load_num_feats(df, num_bool_func)\n",
        "    return cat_feats, num_feats\n",
        "\n",
        "def normalize_numerical_feats(numerical_feats, transformer=None):\n",
        "    if numerical_feats is None or transformer is None:\n",
        "        return numerical_feats\n",
        "    return transformer.transform(numerical_feats)\n",
        "\n",
        "\n",
        "def load_data(data_df,\n",
        "              text_cols,\n",
        "              tokenizer,\n",
        "              label_col,\n",
        "              label_list=None,\n",
        "              categorical_cols=None,\n",
        "              numerical_cols=None,\n",
        "              sep_text_token_str=' ',\n",
        "              categorical_encode_type='ohe',\n",
        "              numerical_transformer=None,\n",
        "              empty_text_values=None,\n",
        "              replace_empty_text=None,\n",
        "              max_token_length=None,\n",
        "              debug=False,\n",
        "              ):\n",
        "    \n",
        "    text_cols_func = convert_to_func(text_cols)\n",
        "    categorical_cols_func = convert_to_func(categorical_cols)\n",
        "    numerical_cols_func = convert_to_func(numerical_cols)\n",
        "\n",
        "    categorical_feats, numerical_feats = load_cat_and_num_feats(data_df,\n",
        "                                                                categorical_cols_func,\n",
        "                                                                numerical_cols_func,\n",
        "                                                                categorical_encode_type)\n",
        "    numerical_feats = normalize_numerical_feats(numerical_feats, numerical_transformer)\n",
        "    texts_cols = get_matching_cols(data_df, text_cols_func)\n",
        "    print(f'Text columns: {texts_cols}')\n",
        "    texts_list = data_df[texts_cols]\n",
        "    print(f'Raw text example: {texts_list.text.iloc[0]}')\n",
        "    hf_model_text_input = tokenizer(list(data_df.text.values), padding=True, truncation=True,\n",
        "                                    max_length=max_token_length)\n",
        "    tokenized_text_ex = ' '.join(tokenizer.convert_ids_to_tokens(hf_model_text_input['input_ids'][0]))\n",
        "    print(f'Tokenized text example: {tokenized_text_ex}')\n",
        "    labels = data_df[label_col].values\n",
        "\n",
        "    return TorchTabularTextDataset(hf_model_text_input, categorical_feats, numerical_feats, labels, data_df, label_list)\n",
        "\n",
        "def load_train_val_test_helper(train_df,\n",
        "                               val_df,\n",
        "                               test_df,\n",
        "                               text_cols,\n",
        "                               tokenizer,\n",
        "                               label_col,\n",
        "                               label_list=None,\n",
        "                               categorical_cols=None,\n",
        "                               numerical_cols=None,\n",
        "                               sep_text_token_str=' ',\n",
        "                               categorical_encode_type='ohe',\n",
        "                               numerical_transformer_method='quantile_normal',\n",
        "                               empty_text_values=None,\n",
        "                               replace_empty_text=None,\n",
        "                               max_token_length=None,\n",
        "                               debug=False):\n",
        "  numerical_transformer = QuantileTransformer(output_distribution='normal')\n",
        "  num_feats = load_num_feats(train_df, convert_to_func(numerical_cols))\n",
        "  numerical_transformer.fit(num_feats)\n",
        "  train_dataset = load_data(train_df,\n",
        "                            text_cols,\n",
        "                            tokenizer,\n",
        "                            label_col,\n",
        "                            label_list,\n",
        "                            categorical_cols,\n",
        "                            numerical_cols,\n",
        "                            sep_text_token_str,\n",
        "                            categorical_encode_type,\n",
        "                            numerical_transformer,\n",
        "                            empty_text_values,\n",
        "                            replace_empty_text,\n",
        "                            max_token_length,\n",
        "                            debug\n",
        "                            )\n",
        "  test_dataset = load_data(test_df,\n",
        "                          text_cols,\n",
        "                          tokenizer,\n",
        "                          label_col,\n",
        "                          label_list,\n",
        "                          categorical_cols,\n",
        "                          numerical_cols,\n",
        "                          sep_text_token_str,\n",
        "                          categorical_encode_type,\n",
        "                          numerical_transformer,\n",
        "                          empty_text_values,\n",
        "                          replace_empty_text,\n",
        "                          max_token_length,\n",
        "                          debug\n",
        "                          )\n",
        "  val_dataset = load_data(val_df,\n",
        "                          text_cols,\n",
        "                          tokenizer,\n",
        "                          label_col,\n",
        "                          label_list,\n",
        "                          categorical_cols,\n",
        "                          numerical_cols,\n",
        "                          sep_text_token_str,\n",
        "                          categorical_encode_type,\n",
        "                          numerical_transformer,\n",
        "                          empty_text_values,\n",
        "                          replace_empty_text,\n",
        "                          max_token_length,\n",
        "                          debug\n",
        "                          )\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "dXvufnCG5ysT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_cols = ['text']\n",
        "# The label col is expected to contain integers from 0 to N_classes - 1\n",
        "label_col = 'type_encoded' \n",
        "categorical_cols = []\n",
        "numerical_cols = ['n_words', 'n_words_unique', 'n_stopwords', 'n_punct', 'mean_w_len', 'n_parag', 'n_contract', 'polarity', 'subjectivity', 'nn_count', 'pr_count', 'vb_count', 'jj_count', 'uh_count', 'cd_count']\n",
        "label_list = ['opinion', 'reporting', 'satire'] # what each label class represents\n",
        "\n",
        "num_splits=4\n",
        "validation_ratio=0.1\n",
        "max_token_length=512\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "data = pd.read_csv('./data/train_t1_nlp.csv', index_col=0)\n",
        "\n",
        "train_df, val_df = train_test_split(data, test_size=validation_ratio, shuffle=True,\n",
        "                                        train_size=1-validation_ratio, random_state=5)\n",
        "\n",
        "test_df = pd.read_csv('./data/dev_t1_nlp.csv', index_col=0)\n",
        "\n",
        "#encode the label\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "articles = data.text.values\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(data['type']) # encode labels as ints\n",
        "\n",
        "counter = 0\n",
        "for entry in le.classes_:\n",
        "  print(f\"{counter}: {entry}\")\n",
        "  counter += 1\n",
        "\n",
        "data[\"type_encoded\"] = labels # add col to train_df with ints for labels\n",
        "\n",
        "#adding values to label to avoid error in code for test set unknown in competition\n",
        "test_df['type_encoded']=train_df[:len(test_df)]['type_encoded'].values\n",
        "\n",
        "#val_df =None\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = load_train_val_test_helper(train_df, val_df,\n",
        "                                              test_df,\n",
        "                                              text_cols, tokenizer,\n",
        "                                              label_col,\n",
        "                                              label_list,\n",
        "                                              categorical_cols,\n",
        "                                              numerical_cols,\n",
        "                                              #sep_text_token_str,\n",
        "                                              #categorical_encode_type,\n",
        "                                              #numerical_transformer_method,\n",
        "                                              #empty_text_values,\n",
        "                                              #replace_empty_text,\n",
        "                                              max_token_length#,\n",
        "                                              #debug\n",
        "                                              )\n",
        "train_datasets = [train_dataset]\n",
        "val_datasets = [val_dataset]\n",
        "test_datasets = [test_dataset]\n",
        "train_dataset = train_datasets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhg3u6xq5Nku",
        "outputId": "7da667dd-8c65-41fa-f615-ed41cf2499ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n",
            "0: opinion\n",
            "1: reporting\n",
            "2: satire\n",
            "15 numerical columns\n",
            "0 categorical columns\n",
            "15 numerical columns\n",
            "Text columns: ['text']\n",
            "Raw text example: Trump threatens military closure at US border to stop migrants\n",
            "\n",
            "Personal Liberty Poll Exercise your right to vote.\n",
            "President Donald Trump said he’ll mobilize the U.S. military to close the border with Mexico to stop an “assault” on the nation by a caravan of migrants from Central America, according to a report by Bloomberg.com.\n",
            "Trump, who ran in 2016 promising to tighten U.S. immigration laws and stanch the inflow of undocumented migrants, has called for cutting off foreign aid to Guatemala, Honduras and El Salvador if they don’t stop the migrants. He claimed Thursday — without providing evidence — that Democrats are backing the human movement to bolster their case for “open borders and existing weak laws.”\n",
            "“In addition to stopping all payments to these countries, which seem to have almost no control over their population, I must, in the strongest of terms, ask Mexico to stop this onslaught — and if unable to do so I will call up the U.S. Military and CLOSE OUR SOUTHERN BORDER!” Trump said on Twitter.\n",
            "Days ago the president threatened to withhold American aid from Honduras, Guatemala and El Salvador if the flow of immigrants wasn’t stopped. This prompted the Honduran Foreign Ministry to urge its citizens not to join the group, according to Reuters.\n",
            "Honduran president Juan Orlando Hernandez said in a public address on Tuesday evening some Hondurans in the caravan had already returned home and the government was preparing to support them. He did not specify how many had turned back.\n",
            "Still, the caravan had grown to about 4,000 people today. NBC News reported that many of those in the caravan are unaccompanied children. Mexico is said to have deployed 500 additional federal police to its border with Guatemala in anticipation of the caravan’s arrival.\n",
            "On Wednesday, Congressman Matt Gaeetz said video footage shows Honduran women and children were being given cash to join the caravan.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (562). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized text example: [CLS] trump threatens military closure at us border to stop migrants personal liberty poll exercise your right to vote . president donald trump said he ’ ll mob ##ili ##ze the u . s . military to close the border with mexico to stop an “ assault ” on the nation by a caravan of migrants from central america , according to a report by bloomberg . com . trump , who ran in 2016 promising to tighten u . s . immigration laws and stan ##ch the in ##flow of undo ##cum ##ented migrants , has called for cutting off foreign aid to guatemala , honduras and el salvador if they don ’ t stop the migrants . he claimed thursday — without providing evidence — that democrats are backing the human movement to bo ##lster their case for “ open borders and existing weak laws . ” “ in addition to stopping all payments to these countries , which seem to have almost no control over their population , i must , in the strongest of terms , ask mexico to stop this onslaught — and if unable to do so i will call up the u . s . military and close our southern border ! ” trump said on twitter . days ago the president threatened to with ##hold american aid from honduras , guatemala and el salvador if the flow of immigrants wasn ’ t stopped . this prompted the hon ##dur ##an foreign ministry to urge its citizens not to join the group , according to reuters . hon ##dur ##an president juan orlando hernandez said in a public address on tuesday evening some hon ##dur ##ans in the caravan had already returned home and the government was preparing to support them . he did not specify how many had turned back . still , the caravan had grown to about 4 , 000 people today . nbc news reported that many of those in the caravan are una ##cco ##mp ##ani ##ed children . mexico is said to have deployed 500 additional federal police to its border with guatemala in anticipation of the caravan ’ s arrival . on wednesday , congressman matt ga ##eet ##z said video footage shows hon ##dur ##an women and children were being given cash to join the caravan . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "DONE TRAIN\n",
            "0 categorical columns\n",
            "15 numerical columns\n",
            "Text columns: ['text']\n",
            "Raw text example: Trump and Melania beam as they pose for photos with leaders of Caribbean nations in Mar-a-Lago\n",
            "\n",
            "Advertisement\n",
            "Donald Trump and the First Lady of the United States didn't appear to be fazed after Robert Mueller handed over his report on the president's Russia connections Friday.\n",
            "POTUS and Melania Trump were grinning from ear-to-ear as they posed for a photo opportunity with Caribbean leaders in Florida as the world waited for a reaction to the probe being officially complete.\n",
            "Standing on the steps of Trump's beloved vacation spot, spectators waited for some indication the Special Counsel news may have stirred them.\n",
            "Scroll down for videos\n",
            "Melania and Donald Trump hosted Caribbean leaders at Mar-a-Lago, Florida on Friday\n",
            "The president and First Lady appeared on the same day Robert Mueller handed in his report on possible Trump collusion election with Russia\n",
            "While her husband is under intense scrutiny, all eyes were on Melania during the photo call.\n",
            "Melania wore a linen silk dress from UK brand LK Bennett featuring distracting bold orange, white and black Aztec-inspired prints.\n",
            "The cinched-in-at-the-waist 'Andrea' round-neck occasion dress is currently on sale for $282.50, down from $565.\n",
            "Melania paired the midi-length half price frock with Christian Louboutin heels.\n",
            "The First Lady had a breezy attitude as she took to social media to speak about her day with Jamaica's Prime Minister Andrew Holness, Haiti President Jovenel Moise, Saint Lucia's Prime Minister Allen Michael Chastanet, Dominican Republic President Danilo Medina, and Bahamas Prime Minister Hubert Minnis.\n",
            "'Enjoyed hosting the leaders & their delegations,' she posted on Twitter about the day at West Palm Beach.\n",
            "They posed with leaders from Jamaica, Haiti, Saint Lucia, Dominican Republic and Bahamas\n",
            "The White House residents said they 'enjoyed' and were 'honored' hosting Caribbean leaders\n",
            "Trump (3rd left) and Melania (center) hosted (left to right) Allen Michael Chastanet, Prime Minister of Saint Lucia; Danilo Medina SÃ¡nchez, President of the Dominican Republic; Andrew Holness, Prime Minister of Jamaica; Jovenel MoÃ¯se, President of the Republic of Haiti; and Hubert A. Minnis, Prime Minister of the Bahamas\n",
            "Earlier Trump had shared a video on Twitter from inside his meeting.\n",
            "Making no mention of the Mueller report, he posted: 'Today in Florida, @FLOTUS and I were honored to welcome and meet with leaders from the Bahamas, Dominican Republic, Haiti, Jamaica, and Saint Lucia!'\n",
            "He arrived on Air Force One at the Palm Beach International Airport waving to supporters.\n",
            "Late on Friday Trump's attorney Rudy Giuliani told Fox News: 'This marks the end of the Russia investigation.\n",
            "We await a disclosure of the facts.\n",
            "We are confident that there is no finding of collusion by the president and this underscores what the president has been saying from the beginning - that he did nothing wrong.'\n",
            "FLOTUS wore distracting dress from UK brand LK Bennett among a sea of men in suits\n",
            "Trump shakes the hand of Allen Michael Chastanet, the Prime Minister of Saint Lucia\n",
            "US President Trump shakes the hand of Hubert A. Minnis, the Prime Minister of the Bahamas\n",
            "The First Lady posted on Twitter as the world learned Robert Mueller had completed his probe\n",
            "Trump turned attention to a staged photo opportunity on the day all eyes were on Russia probe\n",
            "The Robert Mueller-led probe was over Friday.\n",
            "Mueller is pictured arriving at his Washington DC office Thursday night\n",
            "Barr said in a letter to House Judiciary Committee Chairman Jerrold Nadler, D-N.Y.; Ranking Member Doug Collins, R-Ga.; Senate Judiciary Committee Chairman Lindsey Graham, R-S.C.; and Ranking Member Dianne Feinstein, D-Calif., that he 'may be in a position to advise you of the Special Counsel's principal conclusions as soon as this weekend'.\n",
            "'Separately, I intend to consult with Deputy Attorney General Rod Rosenstein and Special Counsel Mueller to determine what other information from the report can be released to Congress and the public consistent with law, including the Special Counsel regulations, and the Department's long-standing practices and policies,' he added Friday.\n",
            "House Speaker Nancy Pelosi, D-Calif., and Senate Minority Leader Chuck Schumer, D-N.Y., said in a joint statement: 'It is imperative for Mr. Barr to make the full report public and provide its underlying documentation and findings to Congress.\n",
            "'Attorney General Barr must not give President Trump, his lawyers or his staff any 'sneak preview' of Special Counsel Mueller's findings or evidence, and the White House must not be allowed to interfere in decisions about what parts of those findings or evidence are made public.'\n",
            "Attorney General William Barr (center) arrives at home in McLean, Virginia on Friday evening\n",
            "Trump's meeting took place on the day it emerged Congress could be briefed on Mueller's report as soon as this weekend\n",
            "But Trump's team said they were confident the findings would show there was no collusion\n",
            "\n",
            "\n",
            "Tokenized text example: [CLS] trump and mel ##ania beam as they pose for photos with leaders of caribbean nations in mar - a - la ##go advertisement donald trump and the first lady of the united states didn ' t appear to be fa ##zed after robert mueller handed over his report on the president ' s russia connections friday . pot ##us and mel ##ania trump were grinning from ear - to - ear as they posed for a photo opportunity with caribbean leaders in florida as the world waited for a reaction to the probe being officially complete . standing on the steps of trump ' s beloved vacation spot , spectators waited for some indication the special counsel news may have stirred them . scroll down for videos mel ##ania and donald trump hosted caribbean leaders at mar - a - la ##go , florida on friday the president and first lady appeared on the same day robert mueller handed in his report on possible trump col ##lusion election with russia while her husband is under intense scrutiny , all eyes were on mel ##ania during the photo call . mel ##ania wore a linen silk dress from uk brand l ##k bennett featuring distracting bold orange , white and black aztec - inspired prints . the ci ##nched - in - at - the - waist ' andrea ' round - neck occasion dress is currently on sale for $ 282 . 50 , down from $ 56 ##5 . mel ##ania paired the midi - length half price fr ##ock with christian lou ##bo ##uti ##n heels . the first lady had a bree ##zy attitude as she took to social media to speak about her day with jamaica ' s prime minister andrew ho ##ln ##ess , haiti president jo ##ven ##el moi ##se , saint lucia ' s prime minister allen michael cha ##stan ##et , dominican republic president dani ##lo medina , and bahamas prime minister hubert min ##nis . ' enjoyed hosting the leaders & their delegation ##s , ' she posted on twitter about the day at west palm beach . they posed with leaders from jamaica , haiti , saint lucia , dominican republic and bahamas the white house residents said they ' enjoyed ' and were ' honored ' hosting caribbean leaders trump ( 3rd left ) and mel ##ania ( center ) hosted ( left to right ) allen michael cha ##stan ##et , prime minister of saint lucia ; dani ##lo medina sa ¡ nc ##he ##z , president of the dominican republic ; andrew ho ##ln ##ess , prime minister of jamaica ; jo ##ven ##el [UNK] , president of the republic of haiti ; and hubert a . min ##nis , prime minister of the bahamas earlier trump had shared a video on twitter from inside his meeting . making no mention of the mueller report , he posted : ' today in florida , @ fl ##ot ##us and i were honored to welcome and meet with [SEP]\n",
            "DONE TEST\n",
            "0 categorical columns\n",
            "15 numerical columns\n",
            "Text columns: ['text']\n",
            "Raw text example: Next inflation shock! One euro now costs 117 cents\n",
            "\n",
            "It just doesn't get any better: inflation in the euro area is increasingly threatening. On Monday afternoon, one euro cost 117 cents for the first time. This is a price jump of 17 percent since the beginning of the year. Experts react concerned.\n",
            "\n",
            "\"It is a questionable development that the inflation does not stop at the euro,\" said Johannes Nebelsiek from the Institute for the World Economy. \"So far, it has been irrefutable that one euro always costs around 100 cents.\"\n",
            "\n",
            "The consequences for consumers and entrepreneurs are painfully noticeable. The fact that everything will become more expensive is explained by itself. There is a new fact that in the event of an off -run amounts or the issuing of temporary allowance will have to be converted differently in the future. Many retailers do not want this to their customers and the health insurance staff and have therefore rounded up all goods prices to entire euro amounts, which reinforces the inflation.\n",
            "\n",
            "Employees who have previously received their salary in cent are particularly affected by the increase of the euro to 117 cents. You will be advised to switch to euros as soon as possible.\n",
            "\n",
            "In view of these developments, according to Nebelsiek, it is now only a matter of time before the cent is also more affected by inflation. \"We must now be prepared for everything,\" explains the expert. \"It would not be surprised if we had to pay up to two cents for a cent before autumn.\"\n",
            "Tokenized text example: [CLS] next inflation shock ! one euro now costs 117 cents it just doesn ' t get any better : inflation in the euro area is increasingly threatening . on monday afternoon , one euro cost 117 cents for the first time . this is a price jump of 17 percent since the beginning of the year . experts react concerned . \" it is a questionable development that the inflation does not stop at the euro , \" said johannes ne ##bel ##sie ##k from the institute for the world economy . \" so far , it has been ir ##re ##fu ##table that one euro always costs around 100 cents . \" the consequences for consumers and entrepreneurs are painfully noticeable . the fact that everything will become more expensive is explained by itself . there is a new fact that in the event of an off - run amounts or the issuing of temporary allowance will have to be converted differently in the future . many retailers do not want this to their customers and the health insurance staff and have therefore rounded up all goods prices to entire euro amounts , which reinforce ##s the inflation . employees who have previously received their salary in cent are particularly affected by the increase of the euro to 117 cents . you will be advised to switch to euros as soon as possible . in view of these developments , according to ne ##bel ##sie ##k , it is now only a matter of time before the cent is also more affected by inflation . \" we must now be prepared for everything , \" explains the expert . \" it would not be surprised if we had to pay up to two cents for a cent before autumn . \" [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "## Train Our Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc490a8-c8b4-4ed4-9e58-f84c3f7fb5cf"
      },
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3) # The number of output labels--2 for binary classification. You can increase this for multi-class tasks.  \n",
        "\n",
        "config.numerical_feat_dim = 15 #numerical_feats.size()[1] #train_dataset.numerical_feats.shape[1]\n",
        "config.cat_feat_dim = 0 #categorical_feats.size()[1]\n",
        "\n",
        "config.text_feat_dim = config.hidden_size #768 for BERT\n",
        "# Load the modified BERT\n",
        "model = BertConcatFeatures.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "desc = model.cuda()\n",
        "#model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "7116e65a019e4cac90a62764e2d61b0b",
            "51bcb35b84f34ced9227e8417233fd4f",
            "461fcc5b5b004c60abb865d686660ae0",
            "aadaaa593b9a4980926031ad4783ad56",
            "614d58a3d2bd4faa9ad271782b047705",
            "8529a114e23940fe91578522254eb42d",
            "0d0641aa74dd4e4a8fd4c49b6d772c00",
            "6f7227ee4efa4027962d227edc9687cb",
            "4371f8a0cff448b5902158400933c5cc",
            "89f64b908d4949de84c6dee57de29013",
            "e3cc03c0a785455da31232323f2c52fa"
          ]
        },
        "id": "R0bP8hUTpTRs",
        "outputId": "b4ff64c4-5446-45d8-a03e-5ab2beaa0ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7116e65a019e4cac90a62764e2d61b0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP layer sizes:\n",
            " Input: 783\n",
            " Hidden: [195, 48, 12]\n",
            " Output: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertConcatFeatures: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertConcatFeatures from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertConcatFeatures from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertConcatFeatures were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.bn.1.weight', 'num_bn.running_var', 'mlp.layers.2.weight', 'mlp.bn.1.bias', 'mlp.bn.2.num_batches_tracked', 'mlp.bn.0.running_var', 'mlp.bn.2.running_var', 'mlp.layers.1.bias', 'mlp.layers.0.bias', 'mlp.layers.3.bias', 'num_bn.weight', 'classifier.bias', 'num_bn.running_mean', 'mlp.bn.0.weight', 'mlp.bn.1.running_var', 'mlp.bn.2.bias', 'mlp.bn.1.num_batches_tracked', 'mlp.layers.2.bias', 'mlp.bn.2.weight', 'mlp.bn.2.running_mean', 'num_bn.bias', 'mlp.bn.0.running_mean', 'classifier.weight', 'mlp.layers.0.weight', 'num_bn.num_batches_tracked', 'mlp.bn.0.num_batches_tracked', 'mlp.layers.1.weight', 'mlp.layers.3.weight', 'mlp.bn.0.bias', 'mlp.bn.1.running_mean']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 3e-3 #grater because the MLP should be trained it has randomly inizialited weights\n",
        "epochs = 10\n",
        "max_len= 512 #set previous to tokenization and encoding the text\n",
        "print('Using maximum sequence length:', max_len)"
      ],
      "metadata": {
        "id": "VwPmsPRExi-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5c44a3-3a09-4d88-debd-77b1e2733062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using maximum sequence length: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_sampler = SequentialSampler(val_dataset)\n",
        "validation_dataloader = DataLoader(val_dataset, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "GaBgq9NbeLy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "from torch.optim import AdamW\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "### 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "#epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 100 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[\"input_ids\"].to(device)\n",
        "        print(b_input_ids[0])\n",
        "        b_categ_feats = batch[\"cat_feats\"].to(device)\n",
        "        b_numer_feats = batch[\"numerical_feats\"].to(device)\n",
        "        b_input_mask = batch[\"attention_mask\"].to(device)\n",
        "        b_labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       cat_feats = b_categ_feats,\n",
        "                       numerical_feats = b_numer_feats)\n",
        "                       #return_dict=True)\n",
        "\n",
        "        #loss = result.loss\n",
        "        loss = result['loss']\n",
        "        logits = result['logits']\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        #print(batch)\n",
        "        #batch = tuple(batch[t].to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        #b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_categ_feats, b_numer_feats = batch\n",
        "        b_input_ids = batch[\"input_ids\"].to(device)\n",
        "        b_categ_feats = batch[\"cat_feats\"].to(device)\n",
        "        b_numer_feats = batch[\"numerical_feats\"].to(device)\n",
        "        b_input_mask = batch[\"attention_mask\"].to(device)\n",
        "        b_labels = batch[\"labels\"].to(device)\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels,\n",
        "                          cat_feats = b_categ_feats,\n",
        "                          numerical_feats = b_numer_feats)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result['loss']\n",
        "        logits = result['logits']\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "## Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "#load saved model\n",
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3) # The number of output labels--2 for binary classification. You can increase this for multi-class tasks.  \n",
        "\n",
        "config.numerical_feat_dim = 15 #numerical_feats.size()[1] #train_dataset.numerical_feats.shape[1]\n",
        "config.cat_feat_dim = 0 #categorical_feats.size()[1]\n",
        "\n",
        "config.text_feat_dim = config.hidden_size #768 for BERT\n",
        "# Load the modified BERT\n",
        "model = BertConcatFeatures.from_pretrained(\n",
        "    \"./drive/My Drive/SemEval2023/t1/models/multifeatures/model_save\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "desc = model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTfTfBiuxZ3V",
        "outputId": "e547fbe5-3a25-4b26-a7e9-21a7a557dfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n",
            "MLP layer sizes:\n",
            " Input: 783\n",
            " Hidden: [195, 48, 12]\n",
            " Output: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size=1\n",
        "# Create the DataLoader for our test set.\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "UENkpbxLwtQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054fec72-6460-4bfb-cecc-ee12ed31568a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test articles...'.format(len(test_dataset)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Measure elapsed time.\n",
        "t0 = time.time()\n",
        "out=[]\n",
        "# Predict \n",
        "for (step, batch) in enumerate(test_dataloader):\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    #batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "    # Progress update every 100 batches.\n",
        "    if step % 10 == 0 and not step == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    #print(batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids = batch[\"input_ids\"].to(device)\n",
        "    b_categ_feats = batch[\"cat_feats\"].to(device)\n",
        "    b_numer_feats = batch[\"numerical_feats\"].to(device)\n",
        "    b_input_mask = batch[\"attention_mask\"].to(device)\n",
        "    b_labels = batch[\"labels\"].to(device)\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():\n",
        "      result = model(b_input_ids, token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels,\n",
        "                          cat_feats = b_categ_feats,\n",
        "                          numerical_feats = b_numer_feats)\n",
        "      \n",
        "    logits = result[\"logits\"]\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 83 test articles...\n",
            "  Batch    10  of     83.    Elapsed: 0:00:00.\n",
            "  Batch    20  of     83.    Elapsed: 0:00:01.\n",
            "  Batch    30  of     83.    Elapsed: 0:00:01.\n",
            "  Batch    40  of     83.    Elapsed: 0:00:01.\n",
            "  Batch    50  of     83.    Elapsed: 0:00:02.\n",
            "  Batch    60  of     83.    Elapsed: 0:00:02.\n",
            "  Batch    70  of     83.    Elapsed: 0:00:02.\n",
            "  Batch    80  of     83.    Elapsed: 0:00:03.\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "pred_flat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UhdIIEBAPAb",
        "outputId": "fd85c056-5060-4b1a-8581-88542f2174ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTBM4ZC6Ac7k",
        "outputId": "23a5c058-ad97-458e-a921-6cf304b8174d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.00174322, -0.02498835,  0.04351984]], dtype=float32),\n",
              " array([[ 0.02438149, -0.02318301,  0.01149505]], dtype=float32),\n",
              " array([[ 0.00874922, -0.03220041,  0.05335634]], dtype=float32),\n",
              " array([[ 0.05109492, -0.0540915 ,  0.01314934]], dtype=float32),\n",
              " array([[ 0.04506254, -0.0419168 ,  0.00394178]], dtype=float32),\n",
              " array([[ 0.05673124, -0.05452375,  0.00840827]], dtype=float32),\n",
              " array([[ 0.01981907, -0.00300261,  0.02190955]], dtype=float32),\n",
              " array([[ 0.05987692, -0.06959213, -0.00100047]], dtype=float32),\n",
              " array([[ 0.02590231, -0.02636886,  0.01477152]], dtype=float32),\n",
              " array([[ 0.01179087, -0.00443309,  0.02531411]], dtype=float32),\n",
              " array([[ 0.05612709, -0.07254086,  0.0212057 ]], dtype=float32),\n",
              " array([[ 0.00581575, -0.01738445,  0.02828153]], dtype=float32),\n",
              " array([[ 0.05396029, -0.03332298, -0.03130833]], dtype=float32),\n",
              " array([[ 0.04896293, -0.03744278,  0.01004206]], dtype=float32),\n",
              " array([[ 0.05221582, -0.0538747 , -0.00391109]], dtype=float32),\n",
              " array([[ 0.03143688, -0.0414087 ,  0.00650614]], dtype=float32),\n",
              " array([[ 0.01253569, -0.01596368,  0.00085157]], dtype=float32),\n",
              " array([[ 0.05279161, -0.03811005, -0.00128573]], dtype=float32),\n",
              " array([[ 0.03993842, -0.05938779, -0.00080695]], dtype=float32),\n",
              " array([[ 0.00894209, -0.01697711,  0.01026323]], dtype=float32),\n",
              " array([[ 0.03887973, -0.02060767,  0.000981  ]], dtype=float32),\n",
              " array([[ 0.05022491, -0.04983807, -0.01478423]], dtype=float32),\n",
              " array([[ 0.04454407, -0.03381257,  0.00393288]], dtype=float32),\n",
              " array([[ 0.03992006, -0.02984547,  0.00300573]], dtype=float32),\n",
              " array([[ 0.03760465, -0.0238262 , -0.01470596]], dtype=float32),\n",
              " array([[ 0.04306014, -0.03104091,  0.00083963]], dtype=float32),\n",
              " array([[ 0.0504636 , -0.03924152, -0.01155884]], dtype=float32),\n",
              " array([[ 0.0437666 , -0.04981972, -0.00113779]], dtype=float32),\n",
              " array([[ 0.02140239, -0.00715894, -0.00226976]], dtype=float32),\n",
              " array([[ 0.02806309, -0.03708889,  0.03067392]], dtype=float32),\n",
              " array([[ 0.06403159, -0.07152223, -0.00135244]], dtype=float32),\n",
              " array([[ 0.05032099, -0.04426116,  0.00986811]], dtype=float32),\n",
              " array([[ 0.04922781, -0.03590016, -0.00842651]], dtype=float32),\n",
              " array([[ 0.02726393, -0.03144957,  0.01152317]], dtype=float32),\n",
              " array([[ 0.01374858, -0.0387276 ,  0.08202589]], dtype=float32),\n",
              " array([[ 0.05214905, -0.0529849 ,  0.01516597]], dtype=float32),\n",
              " array([[ 0.04626195, -0.06695411,  0.01981794]], dtype=float32),\n",
              " array([[ 0.05114529, -0.04338342,  0.01025499]], dtype=float32),\n",
              " array([[ 0.00601587, -0.01913645,  0.0079519 ]], dtype=float32),\n",
              " array([[ 0.06497711, -0.06080351,  0.00249972]], dtype=float32),\n",
              " array([[ 0.02333478, -0.01679004, -0.00113167]], dtype=float32),\n",
              " array([[ 0.04698321, -0.04134417,  0.01904179]], dtype=float32),\n",
              " array([[ 0.06313411, -0.05851771,  0.01648938]], dtype=float32),\n",
              " array([[ 0.05071421, -0.06277559,  0.0320018 ]], dtype=float32),\n",
              " array([[ 0.04857999, -0.07468598, -0.00113462]], dtype=float32),\n",
              " array([[ 0.03785076, -0.03743171,  0.00321479]], dtype=float32),\n",
              " array([[ 0.03449606, -0.05043795,  0.03190717]], dtype=float32),\n",
              " array([[ 0.04204091, -0.04311828,  0.01028387]], dtype=float32),\n",
              " array([[ 0.03623554, -0.04650533,  0.009934  ]], dtype=float32),\n",
              " array([[ 0.05290792, -0.04406488, -0.01595401]], dtype=float32),\n",
              " array([[ 0.03475728, -0.02144922, -0.01170794]], dtype=float32),\n",
              " array([[ 0.03413938, -0.03227536,  0.00565109]], dtype=float32),\n",
              " array([[ 8.0126105e-05, -2.6957400e-02,  8.8139728e-02]], dtype=float32),\n",
              " array([[ 0.01003976, -0.02566934,  0.02040442]], dtype=float32),\n",
              " array([[ 0.06045643, -0.06833827,  0.00373274]], dtype=float32),\n",
              " array([[ 0.05987475, -0.05458213,  0.00795543]], dtype=float32),\n",
              " array([[ 0.05078416, -0.05300824,  0.00529468]], dtype=float32),\n",
              " array([[ 0.05459921, -0.07564902,  0.04299368]], dtype=float32),\n",
              " array([[ 0.01791289, -0.01162594,  0.04625119]], dtype=float32),\n",
              " array([[-0.04312872,  0.09419148,  0.03922163]], dtype=float32),\n",
              " array([[ 0.05033362, -0.04891331,  0.01100233]], dtype=float32),\n",
              " array([[ 0.04713902, -0.04937969, -0.01516043]], dtype=float32),\n",
              " array([[ 0.05142147, -0.04857624, -0.0118135 ]], dtype=float32),\n",
              " array([[ 0.04347417, -0.04828865,  0.01098273]], dtype=float32),\n",
              " array([[ 0.04624526, -0.05013107,  0.01298218]], dtype=float32),\n",
              " array([[ 0.05001176, -0.03601383, -0.01200809]], dtype=float32),\n",
              " array([[ 0.04695331, -0.03592351,  0.00557464]], dtype=float32),\n",
              " array([[ 0.05117997, -0.04705257,  0.02231041]], dtype=float32),\n",
              " array([[ 0.0532113 , -0.04723269,  0.01458476]], dtype=float32),\n",
              " array([[-0.0020409 , -0.00341808, -0.00252646]], dtype=float32),\n",
              " array([[ 0.00323117, -0.01924684,  0.0269996 ]], dtype=float32),\n",
              " array([[ 0.02335343, -0.04428637,  0.0275741 ]], dtype=float32),\n",
              " array([[ 0.04893072, -0.01891829, -0.01874238]], dtype=float32),\n",
              " array([[ 0.00304175, -0.01507213,  0.01273782]], dtype=float32),\n",
              " array([[ 0.04275781, -0.03742986,  0.00090292]], dtype=float32),\n",
              " array([[ 0.06362668, -0.07282726,  0.00589158]], dtype=float32),\n",
              " array([[-0.00412479, -0.00017045,  0.02929054]], dtype=float32),\n",
              " array([[ 0.0332865 , -0.02407538,  0.00980296]], dtype=float32),\n",
              " array([[ 0.05532143, -0.04464196,  0.01140528]], dtype=float32),\n",
              " array([[ 0.06189587, -0.06052774,  0.01035163]], dtype=float32),\n",
              " array([[ 0.05785019, -0.04578362, -0.01160005]], dtype=float32),\n",
              " array([[ 0.04677949, -0.02397061, -0.0238677 ]], dtype=float32),\n",
              " array([[ 0.05810102, -0.05488342,  0.0046828 ]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGL_Vb1g9wFa",
        "outputId": "01e762e9-7799-4ad4-c3b9-8f5f562718a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import trainer\n",
        "trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=build_compute_metrics_fn(task),\n",
        "        )"
      ],
      "metadata": {
        "id": "pW3njbYy75Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlBi2hc-IuVu"
      },
      "source": [
        "# Combine the results across the batches.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzOXklXZOpi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a24081a-84ae-4ed4-a4b5-5b30eb18c005"
      },
      "source": [
        "# Our performance metric for the test set.\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Use the model output for label 1 as our predictions.\n",
        "p1 = predictions[:,1]\n",
        "\n",
        "# Calculate the ROC AUC.\n",
        "auc = roc_auc_score(true_labels, p1)\n",
        "\n",
        "print('Test ROC AUC: %.3f' %auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test ROC AUC: 0.974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUmsUOIv8EUO"
      },
      "source": [
        "## Save Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ba1a7c-c869-4259-a42e-ff817e7a5d9e"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "import os\n",
        "gdrive_path = \"./drive/My Drive/BERTt1/model_save/\"\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(gdrive_path):\n",
        "    os.makedirs(gdrive_path)\n",
        "\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ gdrive_path"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}